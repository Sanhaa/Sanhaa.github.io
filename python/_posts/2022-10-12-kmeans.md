---
layout: post
title: <머신러닝> K-means
description: >
  비지도학습의 한 종류인 K-means 알고리즘
sitemap: false
hide_last_modified: true
---

- Table of Contents
{:toc .large-only}


## 비지도학습

>
ML
- 지도학습 
    1. regression
    2. classification
- 비지도학습 
    1. 차원축소
    2. 클러스터링
- 강화학습

## 숨겨진 구조 (hidden structure)
1. Hard Clustering
    - 데이터 포인트들은 비슷한 것들끼리 뭉쳐있다.
    - ex. 강아지 그룹이거나 고양이 그룹이거나, 둘 중 하나.
    - 대표 알고리즘: K-means, Hierarchical Clustering
2. Soft Clustering
    - 한 개의 데이터 포인트는 숨겨진 클러스터들의 결합이다.
    - ex. 책 장르 분류 (과학 60% + 역사 40 %)
    - 대표 알고리즘: Gaussian Mixture Models (EM, GMM), Soft K-means

## Hard Clustering
- 목표: 비슷한 데이터 포인트끼리 모은다.
- `k`: 클러스터 개수, 찾아야 하는 군집 개수

### Finding K
1. 눈으로 확인
2. 모델이 데이터를 얼마나 잘 설명하는가
    - k 개수를 변화시켜가면서

- 데이터의 특성
- 분석 결과로 얻고자 하는 것 (특정 라벨로 분류, or 분석용인지)


## 차원축소

> 데이터들의 여러 특성들을 2차원, 3차원에 나타내기 위해 차원 축소

### PCA (Principal Componenet Analysis)
> 주성분 분석

1. 고차원의 데이터를 저차원으로 줄이기 위해 (ex. 시각화)
    - 차원이 축소되면서 손실되는 데이터를 줄이는 것이 PCA의 목적 
2. 데이터 정제 (자주 사용)
    - noise 제거


## 클러스터링
> 주어진 데이터를 비슷한 그룹(클러스터)으로 묶는 알고리즘

몇 개의 그룹으로 묶을 건지 (k 값)은 사람이 줌

### K-means
1. 중심 (Centroid)
    > 각 클러스터의 "중심"을 의미
    - 각 데이터 포인트들의 x, y이 평균값

2. 중심과의 거리 (Distance)
    > 중심과 데이터 포인트와의 거리
    - 보통 norm으로 계산: `||x-c||`


**Step 1**
- 중심 위치 잡기 (랜덤)
- 각각의 데이터 포인트들과 임의로 설정한 중심들에 대해 distance 계산
- distance를 비교하여 이 데이터포인트가 어느 클러스터에 속할지 결정
    > A 클러스터의 중심과의 거리가 가깝냐, B 클러스터의 중심과의 거리가 가깝냐

**Step 2**
- 한바퀴 다 돌고 클러스터가 정해지면 *중심점*을 다시 계산
- 중심점 계산법: 해당 클러스터 내 데ㅣ터 포인트 위치의 `무게중심값` (또는 `평균`)

**Step 3**
- Step 1과 2를 반복하면 중심점 업데이트
- 어떠한 데이터 포인트의 할당이 변하지 않을 때까지. (중심점을 옮겼는데도 클러스터링이 같게 나올 때)

### K-means 구현
~~~python

~~~
